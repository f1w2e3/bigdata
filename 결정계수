결정계수에 대해서:

검은색 선은 실제 값이고, 빨간색 선은 평균값이며, 파란색 선은 모델이 예측한 값이다.
i) 만약 파란색 선이 검정색 선에 가깝게 기울어지면 우리는 모델이 잘 학습한 것이라고 판단하고 이를 1에 가까운 값으로 둔다.
ii) 만약 파란색 선이 빨간색 선에 가깝게 기울어지면 우리의 모델은 학습해서 출력한게 평균값과 가깝다는 의미다. 데이터의 실제 값은 검은색 선인데 평균값인 빨간색 선은 사실 어처구니 없을 정도로 데이터 값을 반영하지 못했다.
근데 우리의 모델이 이러한 평균선 근처까지 기울어져버린다면 그건 분명 모델의 학습이 잘 안 되었다는 의미다.
그래서 파란색이 빨간색 선만큼 기울어지면 그걸 0으로 둔다.
iii) 이미 빨간색이라는 평균값까지 기울어진 선만 해도 실제 데이터의 특성을 반영하지 못한다. 그런데 파란선이 만약 이 빨간색 선보다도 더 심하게 기울어진다면 어떨까? 그러면 진짜 못 쓸 정도로 쓰레기 모델인 것이다. 그 정도로 기울어지면 결정계수의 값이 음수로 나온다.

즉 파란선이 검은선에 가까워질수록 1, 
검은선에서 어긋나기 시작하면서부터 1에서 0.9, 0.8, 0.7, … 계속 내려가다가 평균 선인 빨간선까지 도달해버리면 0이 되고
평균선을 지나 더 기울어져버리면 이걸 -0.1, -0.2, -0.3 , … 이런식으로 계속 값이 내려갈 것이다.
그러니까 우리는 모델이 1에 가까운 값으로 출력을 하도록 훈련해야한다.

수학적인 설명:
결정계수의 분모는 파란선과 빨간선 사이의 거리의 합을 나타낸다.
결정계수의 분자는 파란선과 검은선 사이의 거리의 합을 나타낸다.

